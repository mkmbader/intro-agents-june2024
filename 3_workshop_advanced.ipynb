{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An advanced look at LLM Agents\n",
    "## Notebook 3: Agents behind the hood\n",
    "---\n",
    "\n",
    "Previously, we relied on LangChain to to build the agent. However, this is not necessary, since an agent is nothing more than a fancy while loop. \n",
    "\n",
    "**The goal** \n",
    "\n",
    "With this notebook you will see what an agent is under the hood, and you can build it based on the LLM output\n",
    "\n",
    "üåü So ... let us begin!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "\n",
    "1. [Exercise 1: New tool format](#1)\n",
    "2. [Exercise 2: String vs function call response](#2)\n",
    "3. [Exercise 3: Understanding the agent while-loop](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once, if you have not run the following command previously in the terminal. \n",
    "# Afterwards commenting it out  so it does not clutter your notebook.\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions.helper_functions import simple_description_formatter\n",
    "from helper_functions.tools import my_own_wiki_tool, weather_tool\n",
    "import pprint\n",
    "from helper_functions.keys import client\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The tools\n",
    "\n",
    "When querying OpneAI's API directly tools are now called functions (see the API documentation on function calling [here](https://platform.openai.com/docs/assistants/tools/function-calling/quickstart)). Functions have to be passed in a specific JSON format, which we will explore below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: New tool format <a id='1'></a>\n",
    "\n",
    "Compile the cell below and check out the description of the first tool. How does it differ from the previous tool description?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tools and format. In plain OpenAI jargon they are called functions.\n",
    "tools = [my_own_wiki_tool, weather_tool]\n",
    "function_description = [simple_description_formatter(tool) for tool in tools]\n",
    "\n",
    "# Store executable functions with their name in dictionary\n",
    "available_functions = {tool.name: tool for tool in tools}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(function_description[0])\n",
    "\n",
    "# compare this to the description directly obtained from the tool\n",
    "print( #TODO: your code here \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LLM response\n",
    "\n",
    "The LLM can respond with two types of answers:\n",
    "* a string that answers the question, \n",
    "* a function-call object, which contains information on which function to call with which arguments.\n",
    "\n",
    "The second one can be used to execute function calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: String vs function call response <a id='2'></a>\n",
    "\n",
    "Compile both questions, and compare the answers. Do you understand the difference?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a friendly, helpful assistant. Your goal is to answer the questions in a concise, but conversational manner.\"\n",
    "\n",
    "questions = [\"what is the meaning of life?\",\"How many people live in Paris?\"]\n",
    "\n",
    "for question in questions:\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "  \n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools = function_description,\n",
    "    messages=messages, \n",
    "    )\n",
    "\n",
    "  print(f\"Question: {question}\")\n",
    "  print(f\"Answer: {response.choices[0].message.content}\")\n",
    "  print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Agent - a fancy while loop\n",
    "\n",
    "While the LLM requests function calls we \n",
    "* **extract** the **name and arguments** to be called from the initial LLM response,\n",
    "* **execute** the **function calls**,\n",
    "* **store** the **output of the function** in the messages object,\n",
    "* invoke the LLM again, until no function call are requested.\n",
    "\n",
    "For more details, you can also check out this [OpenAI function calling guide](https://platform.openai.com/docs/guides/function-calling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Understanding the agent while-loop <a id='3'></a>\n",
    "\n",
    "Change the question and investigate the output. Do you understand what you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call response:\n",
      "Page: Munich\n",
      "Summary: Munich ( MEW-nik(h); German: M√ºnchen [Ààm èn√ßnÃ©] ) is the capital and most populous city of the Free State of Bavaria, Germany. With a population of 1,589,706 inhabitants as of 29 February 2024, it is the third-largest city in Germany, after Berlin and Hamburg, and thus the largest which does not constitute its own state, as well as the 11th-largest city in the European Union. The city's metropolitan region is home to about 6.2 million people and the third largest metropolitan region by GDP in the European Union.\n",
      "Straddling the banks of the river Isar north of the Alps, Munich is the seat of the Bavarian administrative region of Upper Bavaria, while being the most densely populated municipality in Germany with 4,500 people per km2. Munich is the second-largest city in the Bavarian dialect area, after the Austrian capital of Vienna.\n",
      "The city was first mentioned in 1158. Catholic Munich strongly resisted the Reformation and was a political point of divergence during the resulting Thirty Years' War, but remained physically untouched despite an occupation by the Protestant Swedes. Once Bavaria was established as the Kingdom of Bavaria in 1806, Munich became a major European centre of arts, architecture, culture and science. In 1918, during the German Revolution of 1918‚Äì19, the ruling House of Wittelsbach, which had governed Bavaria since 1180, was forced to abdicate in Munich and a short-lived Bavarian Soviet Republic was declared. In the 1920s, Munich became home to several political factions, among them the Nazi Party. After the Nazis' rise to power, Munich was declared their \"Capital of the Movement\". The city was heavily bombed during World War II, but has restored most of its old town and boasts nearly 30.000 buildings from before the war all over the city. After the end of postwar American occupation in 1949, there was a great increase in population and economic power during the years of Wirtschaftswunder. The city hosted the 1972 Summer Olympics.\n",
      "Today, Munich is a global centre of science, technology, finance, innovation, business, and tourism. Munich enjoys a very high standard and quality of living, reaching first in Germany and third worldwide according to the 2018 Mercer survey, and being rated the world's most liveable city by the Monocle's Quality of Life Survey 2018. Munich is consistently ranked as one of the most expensive cities in Germany in terms of real estate prices and rental costs.\n",
      "In 2021, 28.8 percent of Munich's residents were foreigners, and another 17.7 percent were German citizens with a migration background from a foreign country. Munich's economy is based on high tech, automobiles, and the service sector, as well as IT, biotechnology, engineering, and electronics. It has one of the strongest economies of any German city and the lowest unemployment rate of all cities in Germany with more than one million inhabitants. The city houses many multinational companies, such as BMW, Siemens, Allianz SE and Munich Re. In addition, Munich is home to two research universities, and a multitude of scientific institutions. Munich's numerous architectural and cultural attractions, sports events, exhibitions and its annual Oktoberfest, the world's largest Volksfest, attract considerable tourism.\n",
      "\n",
      "== Intermediate LLM response ==\n",
      "Answer: Paris is larger than Munich in terms of population. Paris has an estimated population of 2,102,650 residents, while Munich has a population of 1,589,706 inhabitants.\n",
      "Function call: None\n",
      "\n",
      "==== Final LLM response ====\n",
      "Question:  which city is bigger: Paris or Munich?\n",
      "Answer: Paris is larger than Munich in terms of population. Paris has an estimated population of 2,102,650 residents, while Munich has a population of 1,589,706 inhabitants.\n",
      "Function call: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"which city is bigger: Paris or Munich?\"\n",
    "\n",
    "messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  tools = function_description,\n",
    "  messages=messages, \n",
    "  )\n",
    "\n",
    "print('==== Initial LLM response ====')\n",
    "print(f\"Answer: {response.choices[0].message.content}\")\n",
    "print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n",
    "# while the response requests function calls\n",
    "while response.choices[0].message.tool_calls:\n",
    "    \n",
    "  # store response message with all function calls\n",
    "  response_message = response.choices[0].message\n",
    "  messages.append(response_message)\n",
    "\n",
    "  # execute each tool individually\n",
    "  for tool_call in response.choices[0].message.tool_calls:\n",
    "    print('==== Function call ====')\n",
    "\n",
    "    # function name and arguments\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    print(f'Calling function \"{function_name}\" with arguments {function_args}.')\n",
    "\n",
    "    # execute function call \n",
    "    function_response = available_functions[function_name].invoke(function_args)\n",
    "    print(f'Function call response:\\n{function_response}\\n')\n",
    "\n",
    "    # append function response to messages\n",
    "    messages.append({\n",
    "        \"tool_call_id\":tool_call.id, \n",
    "        \"role\": \"tool\", \n",
    "        \"name\": function_name, \n",
    "        \"content\": function_response\n",
    "    })\n",
    "    \n",
    "  # get a new response from LLM\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools = function_description,\n",
    "    messages=messages, \n",
    "  )\n",
    "\n",
    "  print('== Intermediate LLM response ==')\n",
    "  print(f\"Answer: {response.choices[0].message.content}\")\n",
    "  print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n",
    "print('==== Final LLM response ====')\n",
    "print(\"Question: \", question)\n",
    "print(f\"Answer: {response.choices[0].message.content}\")\n",
    "print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üåü Congratulations - you've finished the workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
