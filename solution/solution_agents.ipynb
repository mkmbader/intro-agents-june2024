{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildling an LLM Agent with LangChain \n",
    "## Solutions: Agents\n",
    "\n",
    "\n",
    "**Content:**\n",
    "\n",
    "1. [Exercise 1: Explore the agent's output](#1)\n",
    "2. [Exercise 2 : Build your own agent](#2)\n",
    "3. [Exercise 3: Invoke as many tools as you can](#3)\n",
    "4. [Exercise 4 : Optimize the agent prompt](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/mariabader/projects/women_in_ai/intro-agents-june2024'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the path of the current directory (folder_a)\n",
    "current_dir = os.path.dirname(os.path.abspath('.'))\n",
    "\n",
    "# Construct the path of the sibling directory (folder_b)\n",
    "# folder_b_path = os.path.join(current_dir, 'intro-agents-june2024')\n",
    "\n",
    "# folder_b_path = '/Users/mariabader/projects/women_in_ai/intro-agents-june2024'\n",
    "# Add the path of folder_b to the system path\n",
    "# sys.path.append(folder_b_path)\n",
    "\n",
    "# Now you can import your module from folder_b\n",
    "# from my_module import my_function\n",
    "\n",
    "# Use the imported function\n",
    "# my_function()\n",
    "# folder_b_path\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Users/mariabader/projects/women_in_ai/intro-agents-june2024/venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run this cell once, if you have not run the following command previously in the terminal. \n",
    "# Afterwards commenting it out  so it does not clutter your notebook.\n",
    "\n",
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'helper_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OPENAI_KEY\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m my_own_wiki_tool, weather_tool, image_tool\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_tool_calling_agent \u001b[38;5;66;03m# set up the agent\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'helper_functions'"
     ]
    }
   ],
   "source": [
    "from helper_functions.keys import OPENAI_KEY\n",
    "from helper_functions.tools import my_own_wiki_tool, weather_tool, image_tool\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Explore the agent's output <a id='1'></a>\n",
    "\n",
    "**TASK:**\n",
    "In the examples below, read the output to observe how the Agent reasons and decides to use a different tool based on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "\n",
    "# Load Tools\n",
    "tools = [my_own_wiki_tool, weather_tool, image_tool]\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_KEY)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define  the agent (load the LLM and the list of tools)\n",
    "agent = create_tool_calling_agent(llm = llm, tools = tools, prompt = prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"Where is Amsterdam?\"\n",
    "\n",
    "\n",
    "print(f\"Question 1: {question_1}\")\n",
    "agent_executor.invoke({\"input\": question_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"What is the current temperature in Amsterdam?\"\n",
    "\n",
    "print(f\"Question 1: {question_2}\")\n",
    "agent_executor.invoke({\"input\": question_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_3 = \"What should I visit in Amsterdam? Show me an photo\"\n",
    "\n",
    "print(f\"Question 1: {question_3}\")\n",
    "agent_executor.invoke({\"input\": question_3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 : Build your own agent  <a id='2'></a>\n",
    "The goal is to build an agent that uses the tools you previously developed. Feel free to also use the pre-made tools, available at `helper_functions/tools.py`\n",
    "\n",
    "**TASK**: \n",
    "- A template for defining an agent and an API key are already provided to you. Build an agent by using a list of tools, and the LLM `gpt-3.5-turbo-0125`. A template for this agent follows below.\n",
    "- Test if the agent gives an output.\n",
    "- Observe how the output changes if you provide less tools in your list of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component 1 (Tools): Load Tools\n",
    "tools = [\n",
    "    my_own_wiki_tool, weather_tool, image_tool\n",
    "]\n",
    "\n",
    "# Component 2 (LLM): Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", \n",
    "                 temperature=0, \n",
    "                 api_key=OPENAI_KEY)\n",
    "\n",
    "# Component 3 (Prompt): Let the agent know what its purpose is. For now, let's keep it as is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm, tools = tools, prompt = prompt\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Invoke as many tools as you can  <a id='3'></a>\n",
    "\n",
    "**TASK:**\n",
    "Try various questions to call the agent and follow the generated reasoning process in the response. The goal is to call the agent in a way thay it will use as many tools as possible. **Let's see who can reach the highest number of tools used with a single prompt!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** (invoking 2 tools: Wiki and Weather. Can you reach more?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Where is Amsterdam and what is the weather like?\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 : Optimize the agent prompt  <a id='4'></a>\n",
    "So far we played around with the provided LLM and list of tools. Now let's look into the 3rd component: the Agent prompt. \n",
    "\n",
    "**TASK:**\n",
    "- Modify the agent prompt and observe the difference in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**\n",
    "\n",
    "In thi solution we assume you are building an agent for a travel agency, and you want the agent to help you motivate people to visit a city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component 1 (Tools): Load Tools from Exercise 1\n",
    "tools = tools \n",
    "\n",
    "# Component 2 (LLM): Load LLM form Exercise 1\n",
    "llm = llm\n",
    "\n",
    "your_prompt = \"\"\"\"\n",
    "    You are a helpful assisstant, trying to motivate people to go on holiday.\n",
    "\"\"\"\n",
    "\n",
    "#  TODO: enter your code here\n",
    "# Component 3 (Prompt): Create your own prompt to instruct the Agent about its purpose.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", your_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "prompt.messages\n",
    "\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "# This is same as in Exercise 1\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm, tools = tools, prompt = prompt\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe how the same question from before is answered differently with the different prompt.\n",
    "print(f\"Question: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
