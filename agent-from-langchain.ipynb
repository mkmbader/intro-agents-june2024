{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buidling an agent using Langchain\n",
    "\n",
    "Basic building blocks:\n",
    "* Tools: Tools in the context of Large Language Models refer to various functionalities and extensions that enhance the capabilities of these models beyond basic text generation. \n",
    "    * Langchain default tools\n",
    "    * Custom tools\n",
    "* agent: agent llm + prompt + invoke chain\n",
    "* agent executor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ideas**\n",
    "* what about a summarization tool? I'd like to see if we can 1) extract wiki content and then 2) summarize it\n",
    "* Better wiki tool: QA retrieval chain: https://python.langchain.com/v0.1/docs/integrations/retrievers/wikipedia/\n",
    "* this shows how to set up the wikipedia tool as custom tool: https://python.langchain.com/v0.1/docs/modules/tools/\n",
    "* what is the difference between tools and openai functions\n",
    "\n",
    "\n",
    "Use cases:\n",
    "* create an agent that cna combine wikipedia data with relevant real-world information from API's. PRovide comprehensive answers tha encompass historical context and current data (eg weather, )\n",
    "* create agent that can answer questions about specific topics by searching wiki, use NLP to analyze the articles content, summarize the key info and identify relevant sections, provide clear answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo: dependency management\n",
    "\n",
    "# !pip3 install langchain\n",
    "# !pip3 install langchain_openai\n",
    "# !pip3 install langchain_community\n",
    "# pip install wikipedia\n",
    "# pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 freeze > 'dependencies.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises overview\n",
    "1. Familiarize yourself with the default wikipedia tool\n",
    "        <ol type=\"a\">\n",
    "        <li>Explore tool parameters</li>\n",
    "        <li>Run tool and explore output</li>\n",
    "        </ol>\n",
    "2. Build your own tool: weather api\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Langchain default tool: the [Wikipedia tool](https://python.langchain.com/v0.1/docs/integrations/tools/wikipedia/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below loads the full wikipedia tool. It makes an API call to Wikipedia using the ``WikipediaAPIWrapper`` and returns a summary of the queried article. ``WikipediaQueryRun`` then wraps this into a ready made tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)#, doc_content_chars_max=1000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (a): Familiarize yourself with a default tool\n",
    "\n",
    "Use the methods ``name``, ``description``, ``args``, ``return_direct``, ``metadata`` to familiarize yourself with the parameters of the tool. What is the meaning of the different parameters?\n",
    "\n",
    "Background: each tool is a ``BaseTool`` class object, you can find its definition [here](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  wikipedia\n"
     ]
    }
   ],
   "source": [
    "print(\"Name: \", wiki_tool.name)\n",
    "\n",
    "### enter your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # solution: \n",
    "# print(\"Description: \", wiki_tool.description)\n",
    "# print(\"Input argument schema: \", wiki_tool.args)\n",
    "# print(\"Return output to user? \", wiki_tool.return_direct)\n",
    "# print(\"Metadata: \", wiki_tool.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (b)\n",
    "\n",
    "* Use the ``.run(tool_input)`` method to execute the tool. The ``tool_input`` is the search term that you'd like to query wikipedia with.\n",
    "* [Optional] Check out the arguments of the WikipediaAPIWrapper [here](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.wikipedia.WikipediaAPIWrapper.html) and modify its parameters above. How does the output change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: Ruth Bader Ginsburg\n",
      "Summary: Joan Ruth Bader Ginsburg ( BAY-dər GHINZ-burg; née Bader; March 15, 1933 – September 18, 2020) was an American lawyer and jurist who served as an associate justice of the Supreme Court of the United States from 1993 until her death in 2020. She was nominated by President Bill Clinton to replace retiring justice Byron White, and at the time was viewed as a moderate consensus-builder. Ginsburg was the first Jewish woman and the second woman to serve on the Court, after Sandra Day O'Connor. During her tenure, Ginsburg authored the majority opinions in cases such as United States v. Virginia (1996), Olmstead v. L.C. (1999), Friends of the Earth, Inc. v. Laidlaw Environmental Services, Inc. (2000), and City of Sherrill v. Oneida Indian Nation of New York (2005). Later in her tenure, Ginsburg received attention for passionate dissents that reflected liberal views of the law. She was popularly dubbed \"the Notorious R.B.G.\", a moniker she later embraced.\n",
      "Ginsburg was born and grew up in Brooklyn, New York. Her older sister, Marilyn, died of meningitis at the age of six, when Joan was a baby, and her mother died shortly before she graduated from high school. She earned her bachelor's degree at Cornell University and married Martin D. Ginsburg, becoming a mother before starting law school at Harvard, where she was one of the few women in her class. Ginsburg transferred to Columbia Law School, where she graduated joint first in her class. During the early 1960s she worked with the Columbia Law School Project on International Procedure, learned Swedish, and co-authored a book with Swedish jurist Anders Bruzelius; her work in Sweden profoundly influenced her thinking on gender equality. She then became a professor at Rutgers Law School and Columbia Law School, teaching civil procedure as one of the few women in her field.\n",
      "Ginsburg spent much of her legal career as an advocate for gender equality and women's rights, winning many arguments before the Supreme Court. She advocated as a volunteer attorney for the American Civil Liberties Union and was a member of its board of directors and one of its general counsel in the 1970s. In 1980, President Jimmy Carter appointed her to the U.S. Court of Appeals for the District of Columbia Circuit, where she served until her appointment to the Supreme Court in 1993. Between O'Connor's retirement in 2006 and the appointment of Sonia Sotomayor in 2009, she was the only female justice on the Supreme Court. During that time, Ginsburg became more forceful with her dissents, such as with Ledbetter v. Goodyear Tire & Rubber Co. (2007).\n",
      "Despite two bouts with cancer and public pleas from liberal law scholars, she decided not to retire in 2013 or 2014 when President Barack Obama and a Democratic-controlled Senate could appoint and confirm her successor. Ginsburg died at her home in Washington, D.C., in September 2020, at the age of 87, from complications of metastatic pancreatic cancer. The vacancy created by her death was filled 39 days later by Amy Coney Barrett. The result was one of three major rightward shifts in the Court since 1953, following the appointment of Clarence Thomas to replace Thurgood Marshall in 1991 and the appointment of Warren Burger to replace Earl Warren in 1969.\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "query = 'pyladies'\n",
    "query = 'ruth bader ginsburg'\n",
    "\n",
    "print(wiki_tool.run(query))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tools\n",
    "\n",
    "You can build your own tools and don't have to rely on default tools. Tools can be built from any function with the LangChain class method ``StructuredTool.from_function()``(see [here](https://python.langchain.com/v0.1/docs/modules/tools/custom_tools/#structuredtool-dataclass)). The basic elements are\n",
    "* The **function** you would like to be executed when the tool is called\n",
    "* The definition of the **input parameters**\n",
    "* The tool **description**\n",
    "\n",
    "The tool description is especially important, since this is what the agent will use to make the deicion if this tool should be used.\n",
    "\n",
    "Below you see the wikipedia tool, built from the basic elements described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: PyLadies\n",
      "Summary: PyLadies is an international mentorship group which focuses on helping more women become active participants in the Python open-source community. It is part of the Python Software Foundation. It was started in Los Angeles in 2011. The mission of the group is to create a diverse Python community through outreach, education, conferences and social gatherings. PyLadies also provides funding for women to attend open source conferences. The aim of PyLadies is increasing the participation of women in computing. PyLadies became a multi-chapter organization with the founding of the Washington, D.C., chapter in August 2011.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# define the function\n",
    "def wikipedia_caller(query:str) ->str:\n",
    "    \"\"\"This function queries wikipedia through a search query.\"\"\"\n",
    "    return api_wrapper.run(query)\n",
    "\n",
    "# Input parameter definition\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"Input search query\")\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        \"A wrapper around Wikipedia. \"\n",
    "        \"Useful for when you need to answer general questions about \"\n",
    "        \"people, places, companies, facts, historical events, or other subjects. \"\n",
    "        \"Input should be a search query.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "my_own_wiki_tool = StructuredTool.from_function(\n",
    "    func=wikipedia_caller,\n",
    "    name=\"wikipedia\",\n",
    "    description=description,\n",
    "    args_schema=QueryInput,\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(my_own_wiki_tool.run('pyladies'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "The goal is to build a tool that extracts weather information from the weather site visualcrossing.com. You typically need an API key to extract information from a website. In this example we provide you with the API key. \n",
    "\n",
    "Task: \n",
    "- The tool function is already provided to your. Build the tool by defining the input parameters and the descriptions. \n",
    "- Turn function, description and input parameters into a tool through ``StructuredTool.from_function()``\n",
    "- test if the tool gives an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for API calls\n",
    "\n",
    "# define the function\n",
    "def extract_city_weather(city:str)->str:\n",
    "    api_key = 'ZHK4HRAZ3MTNV5FDNQKFYUGL7'\n",
    "\n",
    "    # Build the API URL\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}?key={api_key}&unitGroup=metric\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # extract response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        current_temp = data['days'][0]['temp']\n",
    "        output = f\"Current temperature in {city}: {current_temp}°C\"\n",
    "    else:\n",
    "        output = f\"Error: {response.status_code}\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# Input parameter definition\n",
    "class WeatherInput(BaseModel):\n",
    "    # insert your code here\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        # insert your code here\n",
    "    )\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "weather_tool = StructuredTool.from_function(\n",
    "    # insert your code here\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(weather_tool.run('Amsterdam'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current temperature in Amsterdam: 13.8°C\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# define the function\n",
    "def extract_city_weather(city:str)->str:\n",
    "    api_key = 'ZHK4HRAZ3MTNV5FDNQKFYUGL7'\n",
    "\n",
    "    # Build the API URL\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}?key={api_key}&unitGroup=metric\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        current_temp = data['days'][0]['temp']\n",
    "        output = f\"Current temperature in {city}: {current_temp}°C\"\n",
    "    else:\n",
    "        output = f\"Error: {response.status_code}\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# Input parameter definition\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(description=\"City name\")\n",
    "\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        \"Allows to extract the current temperature in a specific city\"\n",
    "    )\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "weather_tool = StructuredTool.from_function(\n",
    "    func=extract_city_weather,\n",
    "    name=\"weather\",\n",
    "    description=description,\n",
    "    args_schema=WeatherInput,\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(weather_tool.run('Amsterdam'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the individual tools into a list. Your collection of tools is not ready to be used by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tools = [my_own_wiki_tool, weather_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Agent in 3 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub # for the prompt, we are going to skip this\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# agent llm\n",
    "key = 'sk-proj-XX'\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=key)\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent definition\n",
    "agent = create_tool_calling_agent(llm = llm, tools = tools, prompt = prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Ryan Gosling'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Ryan Gosling\n",
      "Summary: Ryan Thomas Gosling ( GOSS-ling; born November 12, 1980) is a Canadian actor. Prominent in both independent films and major studio features, his films have grossed over $2 billion worldwide. Gosling has received various accolades, including a Golden Globe Award, and nominations for three Academy Awards and two British Academy Film Awards.\n",
      "Gosling rose to prominence aged 13 on Disney Channel's The Mickey Mouse Club (1993–1995), and went on to appear in other family entertainment programs, including Are You Afraid of the Dark? (1995) and Goosebumps (1996). His breakthrough role was that of a Jewish neo-Nazi in The Believer (2001), and he gained stardom in the 2004 romantic drama The Notebook. He starred in the critically acclaimed independent dramas Half Nelson (2006), for which he was nominated for the Academy Award for Best Actor; Lars and the Real Girl (2007), and Blue Valentine (2010). \n",
      "In 2011, Gosling had three mainstream successes in the romantic comedy Crazy, Stupid, Love, the political drama The Ides of March, and the action thriller Drive. After making his directorial debut with Lost River (2014), he starred in the financial satire The Big Short (2015), the action comedy The Nice Guys (2016), and the romantic musical La La Land (2016), the latter won him a Golden Globe and a second Academy Award nomination for Best Actor. Further acclaim followed with the science fiction film Blade Runner 2049 (2017) and the biopic First Man (2018). In 2023, he played Ken in the fantasy comedy Barbie, which emerged as his highest-grossing release and earned him a nomination for the Academy Award for Best Supporting Actor.\n",
      "Gosling's band, Dead Man's Bones, released their self-titled debut album and toured North America in 2009. He is a co-owner of Tagine, a Moroccan restaurant in Beverly Hills, California. He is a supporter of PETA, Invisible Children, and the Enough Project and has traveled to Chad, Uganda and eastern Congo to raise awareness about conflicts in the regions. He has been involved in peace promotion efforts in Africa for over a decade. He is in a relationship with actress Eva Mendes, with whom he has two daughters.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `weather` with `{'city': 'Los Angeles'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mCurrent temperature in Los Angeles: 18.0°C\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `weather` with `{'city': 'Toronto'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mCurrent temperature in Toronto: 16.9°C\u001b[0m\u001b[32;1m\u001b[1;3mThe current weather in Los Angeles, where Ryan Gosling lives, is 18.0°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'how is the weather where Ryan gosling lives?',\n",
       " 'output': 'The current weather in Los Angeles, where Ryan Gosling lives, is 18.0°C.'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent_executor.invoke({\"input\": \"who is Ryan Gosling?\"})\n",
    "# agent_executor.invoke({\"input\": \"what is three times 5\"})\n",
    "question = \"How old is Ryan gosling?\"\n",
    "question = 'how many children did ruth bader ginsburg have?'\n",
    "question = 'write me a short summary about ruth bader ginsburg'\n",
    "question = 'what was ruth bader ginsburg passionate about?'\n",
    "question = 'who were ruth baeder ginsburgs colleagues at the supreme court?'\n",
    "question = 'what are great holiday destinations?'\n",
    "question = 'which city is bigger: Paris or Munich?'\n",
    "question = 'which city is better for vacation, Paris or Amsterdam?'\n",
    "question = 'how is the weather where Ryan gosling lives?'\n",
    "\n",
    "agent_executor.invoke({\"input\": question})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens under the hood \n",
    "\n",
    "An agent is nothing more than a while loop: While the LLM expects a function call to be executed, keep querying the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI response: ChatCompletion(id='chatcmpl-9W701XHjMFBbvg6eAC2GTcBiv4nT6', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FXp8H2ased7d8vD7sTtop9ln', function=Function(arguments='{\"query\":\"Population of Paris\"}', name='wikipedia'), type='function')]))], created=1717440429, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=139, total_tokens=155))\n",
      "\n",
      "Calling tool \"wikipedia\" with arguments {'query': 'Population of Paris'}.\n",
      "Function call response:\n",
      "Page: Demographics of Paris\n",
      "Summary: The city of Paris (also called the Commune or Department of Paris) had a population of 2,165,423 people within its administrative city limits as of January 1, 2019. It is surrounded by the Paris unité urbaine, or urban area, the most populous urban area in the European Union. In 2018 the unité urbaine had a population of 10,816,803 in 2,854 km2 (1,102 sq mi). The Paris Region, or Île-de-France, covers 12,012 km2 (4,638 sq mi), and has its own regional council and president. It has a population of 12,213,447 as of January 2018, or 18.3 percent of the population of France. The metropolitan or functional area (aire d'attraction) of Paris covers 18,941 km2 (7,313 sq mi) and has 13,064,617 inhabitants (2018).\n",
      "The population of the city of Paris reached a historic high of 2.9 million in 1921 but then declined; between 1954 and 1999 it declined at every census, falling to 2,125,246 in 1999. After that it began to climb again, reaching 2,240,621 in 2012, but falling to 2,187,526 in 2017.\n",
      "The city's population loss reflected the experience of most other core cities in the developed world that have not expanded their boundaries. The principal factors in the process were a significant decline in household size, and a dramatic migration of residents to the suburbs between 1962 and 1975.  Factors in the migration included deindustrialisation, high rent, the gentrification of many inner quarters, the transformation of living space into offices, and greater affluence among working families. The city's population loss was one of the most severe among international municipalities and the largest for any that had achieved more than 2,000,000 residents.  Since then, an influx of younger residents and immigrants has contributed to the growth of the city.\n",
      "\n",
      "AI response: ChatCompletion(id='chatcmpl-9W702Dgh6ACoVZSdj3xJHHdswf1FK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019.', role='assistant', function_call=None, tool_calls=None))], created=1717440430, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=31, prompt_tokens=609, total_tokens=640))\n",
      "\n",
      "Question:  How many people live in Paris?\n",
      "Final response: The city of Paris had a population of 2,165,423 people within its administrative city limits as of January 1, 2019.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from helper_functions import simple_description_formatter\n",
    "import json\n",
    "client = OpenAI(api_key = key)\n",
    "\n",
    "# format tool description\n",
    "function_tools = [simple_description_formatter(tool) for tool in tools]\n",
    "\n",
    "# extract available functions from list of tools\n",
    "available_functions = {tool.name: tool for tool in tools}\n",
    "\n",
    "question = \"How many people live in Paris?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]\n",
    "\n",
    "\n",
    "# first response\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  tools = function_tools,\n",
    "  messages=messages, \n",
    "  )\n",
    "\n",
    "print(f\"AI response: {response}\\n\")\n",
    "\n",
    "while response.choices[0].message.tool_calls:\n",
    "    \n",
    "    # response message with marameters needed for function call\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    #extract tool calls\n",
    "    tool_calls = response.choices[0].message.tool_calls\n",
    "\n",
    "    for tool_call in tool_calls:\n",
    "        # function name\n",
    "        function_name = response.choices[0].message.tool_calls[0].function.name\n",
    "        \n",
    "        # function arguments\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(f'Calling tool \"{function_name}\" with arguments {function_args}.')\n",
    "\n",
    "        # execute function call \n",
    "        function_response = available_functions[function_name].invoke(function_args)\n",
    "        print(f'Function call response:\\n{function_response}\\n')\n",
    "\n",
    "        # append function response to messages\n",
    "        messages.append({\n",
    "            \"tool_call_id\":tool_call.id, \n",
    "            \"role\": \"tool\", \n",
    "            \"name\": function_name, \n",
    "            \"content\": function_response\n",
    "        })\n",
    "      \n",
    "        # get a new response from LLM\n",
    "        response = client.chat.completions.create(\n",
    "          model=\"gpt-3.5-turbo\",\n",
    "          tools = function_tools,\n",
    "          messages=messages, \n",
    "        )\n",
    "        print(f\"AI response: {response}\\n\")\n",
    "\n",
    "print(\"Question: \", question)\n",
    "print(f\"Final response: {response.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "* https://python.langchain.com/docs/modules/agents/quick_start/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
