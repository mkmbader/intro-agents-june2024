{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An advanced look at LLM Agents\n",
    "\n",
    "Previously, we relied on LangChain to to build the agent. However, this is not necessary, since an agent is nothing more than a fancy while loop. \n",
    "\n",
    "**The goal** \n",
    "\n",
    "With this notebook you will see what an agent is under the hood, and you can build it based on the LLM output\n",
    "\n",
    "ðŸŒŸ So ... let us begin!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The steps**\n",
    "\n",
    "0. [Install dependencies to get the project up and running](#0)\n",
    "1. [Familiarize yourself with the default wikipedia tool](#1)\n",
    "        <ol type=\"a\">\n",
    "        <li>[Explore tool parameters](#1a)</li>\n",
    "        <li>[Run tool and explore output](#1b)</li>\n",
    "        </ol>\n",
    "2. [Build your own tool: weather api](#2)\n",
    "3. Agent exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies <a id='0'></a>\n",
    "\n",
    "Compile the cell below to install the dependencies. Consider clearing the cell output so it does not clutter your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv         \n",
    "!source venv/bin/activate     \n",
    "!pip3 install -r helper_functions/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The key elements\n",
    "\n",
    "The key elements of the agent remain - we need tools, an LLM that functions as the agent and a prompt with the query. In our example, we'll use ``chatgpt35-turbo`` as the agent LLM, [here](https://platform.openai.com/docs/guides/text-generation/chat-completions-api) you find the documentation on how to query the model through the OpenAI API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maria/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': {'description': 'wikipedia(query: str) -> str - A wrapper around '\n",
      "                             'Wikipedia. Useful for when you need to answer '\n",
      "                             'general questions about people, places, '\n",
      "                             'companies, facts, historical events, or other '\n",
      "                             'subjects. Input should be a search query.',\n",
      "              'name': 'wikipedia',\n",
      "              'parameters': {'properties': {'query': {'description': 'Input '\n",
      "                                                                     'search '\n",
      "                                                                     'query',\n",
      "                                                      'type': 'string'}},\n",
      "                             'required': ['query'],\n",
      "                             'type': 'object'}},\n",
      " 'type': 'function'}\n"
     ]
    }
   ],
   "source": [
    "from helper_functions.helper_functions import simple_description_formatter\n",
    "from helper_functions.tools import my_own_wiki_tool, weather_tool\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "# load the tools and format. In plain OpenAI jargon they are called functions.\n",
    "tools = [my_own_wiki_tool, weather_tool]\n",
    "function_description = [simple_description_formatter(tool) for tool in tools]\n",
    "pprint.pprint(function_description[0])\n",
    "\n",
    "# Store executable functions with their name in dictionary\n",
    "available_functions = {tool.name: tool for tool in tools}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the prompt is feed as part of the messages object. All input, such as the system prompt, the user question, possibly also chat-history is provided through this object.\n",
    "Exercise: compile both questions, and compare the answers. Do you see a difference?\n",
    "\n",
    "The LLM can output two types of answers:\n",
    "* a string that answers the question, \n",
    "* a function-call object, which contains information on which function to call with which arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the meaning of life?\n",
      "Answer: Ah, the age-old question! The meaning of life is a philosophical and existential inquiry that has intrigued humans for centuries. It is a deeply personal and subjective matter, with answers varying greatly depending on individual beliefs, values, and experiences. Some find meaning in relationships, personal growth, helping others, spirituality, or pursuing happiness. Ultimately, the meaning of life is a journey for each person to explore and define for themselves.\n",
      "Fuction call: None\n",
      "\n",
      "Question: How many people live in Paris?\n",
      "Answer: None\n",
      "Fuction call: [ChatCompletionMessageToolCall(id='call_NpPrg1E5BmhfqGYhJt2C8lUN', function=Function(arguments='{\"query\":\"Population of Paris\"}', name='wikipedia'), type='function')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from helper_functions.keys import client\n",
    "\n",
    "\n",
    "system_prompt = \"You are a friendly, helpful assistant. Your goal is to answer the questions in a concise, but conversational manner.\"\n",
    "\n",
    "questions = [\"what is the meaning of life?\",\"How many people live in Paris?\"]\n",
    "\n",
    "for question in questions:\n",
    "  messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "  \n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools = function_description,\n",
    "    messages=messages, \n",
    "    )\n",
    "\n",
    "  print(f\"Question: {question}\")\n",
    "  print(f\"Answer: {response.choices[0].message.content}\")\n",
    "  print(f\"Fuction call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the magic: While the LLM requests function calls we \n",
    "* store the response object in the messages\n",
    "* extract per tool the name and the argmemnts of the function to be called\n",
    "* execute the function\n",
    "* store the output of the function in the messages object\n",
    "\n",
    "for more, follow the guide [here](https://platform.openai.com/docs/guides/function-calling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a friendly, helpful assistant. Your goal is to answer the questions in a concise, but conversational manner.'},\n",
       " {'role': 'user', 'content': 'which city is bigger: Paris or Munich?'},\n",
       " ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_G2QXZk2u5vTP2Q79VpAspo5R', function=Function(arguments='{\"query\": \"Paris\"}', name='wikipedia'), type='function'), ChatCompletionMessageToolCall(id='call_vf5iVlKnhpCfHC5jXDuGwSLs', function=Function(arguments='{\"query\": \"Munich\"}', name='wikipedia'), type='function')]),\n",
       " {'tool_call_id': 'call_G2QXZk2u5vTP2Q79VpAspo5R',\n",
       "  'role': 'tool',\n",
       "  'name': 'wikipedia',\n",
       "  'content': \"Page: Paris\\nSummary: Paris is the capital and largest city of France. With an official estimated population of 2,102,650 residents as of 1 January 2023 in an area of more than 105 km2 (41 sq mi), Paris is the fourth-largest city in the European Union and the 30th most densely populated city in the world in 2022. Since the 17th century, Paris has been one of the world's major centres of finance, diplomacy, commerce, culture, fashion, and gastronomy. For its leading role in the arts and sciences, as well as its early and extensive system of street lighting, in the 19th century, it became known as the City of Light. \\nThe City of Paris is the centre of the ÃŽle-de-France region, or Paris Region, with an official estimated population of 12,271,794 inhabitants on 1 January 2023, or about 19% of the population of France. The Paris Region had a GDP of â‚¬765 billion (US$1.064 trillion, PPP) in 2021, the highest in the European Union. According to the Economist Intelligence Unit Worldwide Cost of Living Survey, in 2022, Paris was the city with the ninth-highest cost of living in the world.\\nParis is a major railway, highway, and air-transport hub served by two international airports: Charles de Gaulle Airport (the third-busiest airport in Europe) and Orly Airport. Opened in 1900, the city's subway system, the Paris MÃ©tro, serves 5.23 million passengers daily; it is the second-busiest metro system in Europe after the Moscow Metro. Gare du Nord is the 24th-busiest railway station in the world and the busiest outside Japan, with 262 million passengers in 2015. Paris has one of the most sustainable transportation systems and is one of only two cities in the world that received the Sustainable Transport Award twice.\\nParis is known for its museums and architectural landmarks: the Louvre received 8.9 million visitors in 2023, on track for keeping its position as the most-visited art museum in the world. The MusÃ©e d'Orsay, MusÃ©e Marmottan Monet and MusÃ©e de l'Orangerie are noted for their collections of French Impressionist art. The Pompidou Centre MusÃ©e National d'Art Moderne, MusÃ©e Rodin and MusÃ©e Picasso are noted for their collections of modern and contemporary art. The historical district along the Seine in the city centre has been classified as a UNESCO World Heritage Site since 1991.\\nParis is home to several United Nations organizations including UNESCO, as well as other international organizations such as the OECD, the OECD Development Centre, the International Bureau of Weights and Measures, the International Energy Agency, the International Federation for Human Rights, along with European bodies such as the European Space Agency, the European Banking Authority and the European Securities and Markets Authority. The football club Paris Saint-Germain and the rugby union club Stade FranÃ§ais are based in Paris. The 81,000-seat Stade de France, built for the 1998 FIFA World Cup, is located just north of Paris in the neighbouring commune of Saint-Denis. Paris hosts the annual French Open Grand Slam tennis tournament on the red clay of Roland Garros. The city hosted the Olympic Games in 1900 and 1924, and will host the 2024 Summer Olympics. The 1938 and 1998 FIFA World Cups, the 2019 FIFA Women's World Cup, the 2007 Rugby World Cup, as well as the 1960, 1984 and 2016 UEFA European Championships were also held in the city. Every July, the Tour de France bicycle race finishes on the Avenue des Champs-Ã‰lysÃ©es in Paris.\\n\\n\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Initial LLM response ====\n",
      "Answer: None\n",
      "Function call: [ChatCompletionMessageToolCall(id='call_CVZj8JoHIpJn9H4ltCOXhDZB', function=Function(arguments='{\"city\":\"The Hague\"}', name='weather'), type='function')]\n",
      "\n",
      "==== Function call ====\n",
      "Calling function \"weather\" with arguments {'city': 'The Hague'}.\n",
      "Function call response:\n",
      "Current temperature in The Hague: 14.1Â°C\n",
      "\n",
      "== Intermediate LLM response ==\n",
      "Answer: The current temperature in The Hague, where the King of the Netherlands lives, is 14.1Â°C.\n",
      "Function call: None\n",
      "\n",
      "==== Final LLM response ====\n",
      "Question:  How is the weather where the king of the netherlands lives?\n",
      "Answer: The current temperature in The Hague, where the King of the Netherlands lives, is 14.1Â°C.\n",
      "Function call: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# question = \"How many people live in Paris?\"\n",
    "# question = \"which city is bigger: Paris or Munich?\"\n",
    "question = 'How is the weather where the king of the netherlands lives?'\n",
    "\n",
    "messages = [\n",
    "      {\"role\": \"system\", \"content\": system_prompt},\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  tools = function_description,\n",
    "  messages=messages, \n",
    "  )\n",
    "\n",
    "print('==== Initial LLM response ====')\n",
    "print(f\"Answer: {response.choices[0].message.content}\")\n",
    "print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n",
    "# while the response requests function calls\n",
    "while response.choices[0].message.tool_calls:\n",
    "    \n",
    "  # store response message with all function calls\n",
    "  response_message = response.choices[0].message\n",
    "  messages.append(response_message)\n",
    "\n",
    "  # execute each tool individually\n",
    "  for tool_call in response.choices[0].message.tool_calls:\n",
    "    print('==== Function call ====')\n",
    "\n",
    "    # function name and arguments\n",
    "    function_name = tool_call.function.name\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    print(f'Calling function \"{function_name}\" with arguments {function_args}.')\n",
    "\n",
    "    # execute function call \n",
    "    function_response = available_functions[function_name].invoke(function_args)\n",
    "    print(f'Function call response:\\n{function_response}\\n')\n",
    "\n",
    "    # append function response to messages\n",
    "    messages.append({\n",
    "        \"tool_call_id\":tool_call.id, \n",
    "        \"role\": \"tool\", \n",
    "        \"name\": function_name, \n",
    "        \"content\": function_response\n",
    "    })\n",
    "    \n",
    "  # get a new response from LLM\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools = function_description,\n",
    "    messages=messages, \n",
    "  )\n",
    "\n",
    "  print('== Intermediate LLM response ==')\n",
    "  print(f\"Answer: {response.choices[0].message.content}\")\n",
    "  print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")\n",
    "\n",
    "print('==== Final LLM response ====')\n",
    "print(\"Question: \", question)\n",
    "print(f\"Answer: {response.choices[0].message.content}\")\n",
    "print(f\"Function call: {response.choices[0].message.tool_calls}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
