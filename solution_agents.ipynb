{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildling an LLM Agent with LangChain \n",
    "## Solutions: Agents\n",
    "\n",
    "\n",
    "**Content:**\n",
    "\n",
    "1. [Exercise 1: Explore the agent's output](#1)\n",
    "2. [Exercise 2 : Build your own agent](#2)\n",
    "3. [Exercise 3: Invoke as many tools as you can](#3)\n",
    "4. [Exercise 4 : Optimize the agent prompt](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell once, if you have not run the following command previously in the terminal. \n",
    "# Afterwards commenting it out  so it does not clutter your notebook.\n",
    "\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions.keys import OPENAI_KEY\n",
    "from helper_functions.tools import my_own_wiki_tool, weather_tool, image_tool\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Explore the agent's output <a id='1'></a>\n",
    "\n",
    "**TASK:**\n",
    "In the examples below, read the output to observe how the Agent reasons and decides to use a different tool based on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent\n",
    "\n",
    "# Load Tools\n",
    "tools = [my_own_wiki_tool, weather_tool, image_tool]\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_KEY)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define  the agent (load the LLM and the list of tools)\n",
    "agent = create_tool_calling_agent(llm = llm, tools = tools, prompt = prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"Where is Amsterdam?\"\n",
    "\n",
    "\n",
    "print(f\"Question 1: {question_1}\")\n",
    "agent_executor.invoke({\"input\": question_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"What is the current temperature in Amsterdam?\"\n",
    "\n",
    "print(f\"Question 1: {question_2}\")\n",
    "agent_executor.invoke({\"input\": question_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_3 = \"What should I visit in Amsterdam? Show me an photo\"\n",
    "\n",
    "print(f\"Question 1: {question_3}\")\n",
    "agent_executor.invoke({\"input\": question_3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2 : Build your own agent  <a id='2'></a>\n",
    "The goal is to build an agent that uses the tools you previously developed. Feel free to also use the pre-made tools, available at `helper_functions/tools.py`\n",
    "\n",
    "**TASK**: \n",
    "- A template for defining an agent and an API key are already provided to you. Build an agent by using a list of tools, and the LLM `gpt-3.5-turbo-0125`. A template for this agent follows below.\n",
    "- Test if the agent gives an output.\n",
    "- Observe how the output changes if you provide less tools in your list of tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component 1 (Tools): Load Tools\n",
    "tools = [\n",
    "    my_own_wiki_tool, weather_tool, image_tool\n",
    "]\n",
    "\n",
    "# Component 2 (LLM): Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", \n",
    "                 temperature=0, \n",
    "                 api_key=OPENAI_KEY)\n",
    "\n",
    "# Component 3 (Prompt): Let the agent know what its purpose is. For now, let's keep it as is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm, tools = tools, prompt = prompt\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Invoke as many tools as you can  <a id='3'></a>\n",
    "\n",
    "**TASK:**\n",
    "Try various questions to call the agent and follow the generated reasoning process in the response. The goal is to call the agent in a way thay it will use as many tools as possible. **Let's see who can reach the highest number of tools used with a single prompt!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:** (invoking 2 tools: Wiki and Weather. Can you reach more?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "Where is Amsterdam and what is the weather like?\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4 : Optimize the agent prompt  <a id='4'></a>\n",
    "So far we played around with the provided LLM and list of tools. Now let's look into the 3rd component: the Agent prompt. \n",
    "\n",
    "**TASK:**\n",
    "- Modify the agent prompt and observe the difference in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTION:**\n",
    "\n",
    "In thi solution we assume you are building an agent for a travel agency, and you want the agent to help you motivate people to visit a city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component 1 (Tools): Load Tools from Exercise 1\n",
    "tools = tools \n",
    "\n",
    "# Component 2 (LLM): Load LLM form Exercise 1\n",
    "llm = llm\n",
    "\n",
    "your_prompt = \"\"\"\"\n",
    "    You are a helpful assisstant, trying to motivate people to go on holiday.\n",
    "\"\"\"\n",
    "\n",
    "#  TODO: enter your code here\n",
    "# Component 3 (Prompt): Create your own prompt to instruct the Agent about its purpose.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", your_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])\n",
    "prompt.messages\n",
    "\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "# This is same as in Exercise 1\n",
    "agent = create_tool_calling_agent(\n",
    "    llm = llm, tools = tools, prompt = prompt\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observe how the same question from before is answered differently with the different prompt.\n",
    "print(f\"Question: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
