{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buildling an LLM Agent with LangChain\n",
    "\n",
    "**The goal** \n",
    "\n",
    "The goal is to build an agent that uses the tools you previously developed.\n",
    "\n",
    "ðŸŒŸ So ... let us begin!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The steps**\n",
    "\n",
    "0. [Install dependencies to get the project up and running](#0)\n",
    "1. [Build your own agent](#1)\n",
    "2. [Invoke as many tools as you can](#2)\n",
    "3. [Optimize the agent prompt](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies <a id='0'></a>\n",
    "\n",
    "Compile the cell below to install the dependencies. Consider clearing the cell output so it does not clutter your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv         \n",
    "!source venv/bin/activate     \n",
    "!pip3 install -r helper_functions/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update helper_functions.keys.py based on private bin link\n",
    "from helper_functions.keys import WEATHER_KEY, OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 : Build your own agent  <a id='1'></a>\n",
    "The goal is to build an agent that uses the tools you previously developed. Feel free to also use the pre-made tools, available at `helper_functions/tools.py`\n",
    "\n",
    "Task: \n",
    "- A template for defining an agent and an API key are  already provided to your. Build the agent by providing a list of tools, and an LLM `gpt-3.5-turbo-0125`.\n",
    "- Test if the agent gives an output.\n",
    "- Observe how the output changes if you provide less tools in your list of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions.tools import image_tool, weather_tool, my_own_wiki_tool\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub\n",
    "\n",
    "# Load Tools\n",
    "tools = [\n",
    "# TODO: insert your code here\n",
    "]\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model= # TODO: insert your code here           \n",
    "                 temperature=0, \n",
    "                 api_key=OPENAI_KEY)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is. But for now, let's keep it as is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    # TODO: insert your code here\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    # TODO: insert your code here\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Invoke as many tools as you can  <a id='2'></a>\n",
    "Try various prompts to call the agent and follow the generated reasoning process in the response. The goal is to call the agent in a way thay it will use as many tools as possible. \n",
    "\n",
    "Let's see who can reach the highest number of tools used with a single prompt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\n",
    "#TODO: Insert your code here\n",
    "\"\n",
    "\n",
    "print(f\"Question 1: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 : Optimize the agent prompt  <a id='3'></a>\n",
    "So far we played around with the provided LLM and list of tools. Now let's look into the 3rd component: the Agent promot. \n",
    "\n",
    "Task:\n",
    "- Modify the agent prompt and observe the difference in the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
