{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LLM Agents with LangChain\n",
    "\n",
    "Welcome to the workshop on building LLM agents with LangChain!\n",
    "\n",
    "**The goal** \n",
    "\n",
    "With this notebook you will familiarize yourself with the key concepts of an LLM agent. At the end, you will have all the code you need for your very own agent and you will be able to build custom tools for your own use-case. \n",
    "\n",
    "ðŸŒŸ So ... let us begin!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The use case** \n",
    "\n",
    "Summer holidays are coming up and you still don't know where to go. Oh no! \n",
    "\n",
    "You decide to build a tool that helps you get information on holiday locations. For example, you would like to to find out how big a specific city is, what sights are there to see, how the weather there is, and you would like to get a drawing of that place, to get a first impression. Because who does not like art? \n",
    "\n",
    "You will implement this through a sentinent LLM agent, who has access to\n",
    "* the wikipedia API,\n",
    "* a weather API,\n",
    "* can generate images by using a HuggingFace API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The steps**\n",
    "\n",
    "0. [Install dependencies to get the project up and running](#0)\n",
    "1. [Familiarize yourself with the default wikipedia tool](#1)\n",
    "        <ol type=\"a\">\n",
    "        <li>[Explore tool parameters](#1a)</li>\n",
    "        <li>[Run tool and explore output](#1b)</li>\n",
    "        </ol>\n",
    "2. [Build your own tool: weather api](#2)\n",
    "3. Agent exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies <a id='0'></a>\n",
    "\n",
    "Compile the cell below to install the dependencies. Consider clearing the cell output so it does not clutter your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m venv venv         \n",
    "# !source venv/bin/activate     \n",
    "# !pip3 install -r helper_functions/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Langchain default tool: the [Wikipedia tool](https://python.langchain.com/v0.1/docs/integrations/tools/wikipedia/) <a id='1'></a>\n",
    "\n",
    "The cell below loads the full wikipedia tool. It makes an API call to Wikipedia using the ``WikipediaAPIWrapper`` and returns a summary of the queried article. ``WikipediaQueryRun`` then wraps this into a ready made tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)#, doc_content_chars_max=1000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (a): Familiarize yourself with a default tool <a id='1a'></a>\n",
    "\n",
    "Use the methods ``name``, ``description``, ``args``, ``return_direct``, ``metadata`` to familiarize yourself with the parameters of the tool. What is the meaning of the different parameters?\n",
    "\n",
    "Background: each tool is a ``BaseTool`` class object, you can find its definition [here](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Name: \", wiki_tool.name)\n",
    "\n",
    "### TODO: insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (b) run tool and explore output <a id='1b'></a>\n",
    "\n",
    "* Use the ``.run(tool_input)`` method to execute the tool. The ``tool_input`` is the search term that you'd like to query wikipedia with.\n",
    "* [Optional] Check out the arguments of the WikipediaAPIWrapper [here](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.wikipedia.WikipediaAPIWrapper.html) and modify its parameters above. How does the output change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tools\n",
    "\n",
    "You can build your own tools and don't have to rely on default tools. Tools can be built from any function with the LangChain class method ``StructuredTool.from_function()``(see [here](https://python.langchain.com/v0.1/docs/modules/tools/custom_tools/#structuredtool-dataclass)). The basic elements are\n",
    "* The **function** you would like to be executed when the tool is called\n",
    "* The definition of the **input parameters**\n",
    "* The tool **description**\n",
    "\n",
    "The tool description is especially important, since this is what the agent will use to make the deicion if this tool should be used.\n",
    "\n",
    "Below you see the wikipedia tool, built from the basic elements described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# define the function\n",
    "def wikipedia_caller(query:str) ->str:\n",
    "    \"\"\"This function queries wikipedia through a search query.\"\"\"\n",
    "    return api_wrapper.run(query)\n",
    "\n",
    "# Input parameter definition\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"Input search query\")\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        \"A wrapper around Wikipedia. \"\n",
    "        \"Useful for when you need to answer general questions about \"\n",
    "        \"people, places, companies, facts, historical events, or other subjects. \"\n",
    "        \"Input should be a search query.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "my_own_wiki_tool = StructuredTool.from_function(\n",
    "    func=wikipedia_caller,\n",
    "    name=\"wikipedia\",\n",
    "    description=description,\n",
    "    args_schema=QueryInput,\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(my_own_wiki_tool.run('pyladies'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Build your own tool: weather api <a id='2'></a>\n",
    "The goal is to build a tool that extracts weather information from the weather site visualcrossing.com. You typically need an API key to extract information from a website. In this example we provide you with the API key. \n",
    "\n",
    "Task: \n",
    "- The tool function is already provided to your. Build the tool by defining the input parameters and the descriptions. \n",
    "- Turn function, description and input parameters into a tool through ``StructuredTool.from_function()``\n",
    "- test if the tool gives an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for API calls\n",
    "\n",
    "# define the function\n",
    "def extract_city_weather(city:str)->str:\n",
    "    api_key = 'ZHK4HRAZ3MTNV5FDNQKFYUGL7'\n",
    "\n",
    "    # Build the API URL\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}?key={api_key}&unitGroup=metric\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # extract response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        current_temp = data['days'][0]['temp']\n",
    "        output = f\"Current temperature in {city}: {current_temp}Â°C\"\n",
    "    else:\n",
    "        output = f\"Error: {response.status_code}\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# Input parameter definition\n",
    "class WeatherInput(BaseModel):\n",
    "    # insert your code here\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        # TODO: insert your code here\n",
    "    )\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "weather_tool = StructuredTool.from_function(\n",
    "    # TODO: insert your code here\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(weather_tool.run('Amsterdam'))\n",
    "\n",
    "# TODO: try generating more ouputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the individual tools into a list. Your collection of tools is not ready to be used by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [my_own_wiki_tool, weather_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Agents combine the functionality of two components: LLMs and Tools. They empower an LLM to be able to execute additional tasks and reason through a problem. Namely, LLMs have knowlegde on data that was used at time of training. However, they lack knowledge about up-to-date happenings and information. They consist of the following components: \n",
    "- **LLM**: A pre-trained LLM.\n",
    "- **List of tools**: List of tools that give additional functionality to the LLM.\n",
    "- **Prompt**: A description/guideline that is given to the Agent to create \"awareness\" of its purpose.\n",
    "\n",
    "One use case of LLM Agents is to make it possible to have LLMs with access to real time information, like the current weather. Namely, when a prompt is called, agents have an LLM and Tools at their disposal. Based on the prompt, they can deide what would be a better fit for the given prompt: information already available to the LLM, or information that can be fetched with an API (Tool). E.g. for a given prompt \"What is the **usual** temperature in Amsterdam in summer?\", an LLM will likely already have knowledge. However, a prompt \"What is the **cureent** temperature in Amsterdam?\", a weather API would be a better source of information, and in this case the Agent will decide to use the information from a weather tool. If such a tool is not available to the angent, the agent will repsond that the requested information is not available. \n",
    "\n",
    "So, basically, you can think of Agents as usual LLMs but with more \"skills\". Cool, right?\n",
    "\n",
    "Let's see this through an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub # for the prompt, we are going to skip this\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "\n",
    "\n",
    "from helper_functions.tools import weather_tool, my_own_wiki_tool, image_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "Your agent is ready.\n"
     ]
    }
   ],
   "source": [
    "# Load Tools\n",
    "tools = [my_own_wiki_tool, weather_tool, image_tool]\n",
    "\n",
    "# Load LLM\n",
    "key = 'sk-proj-5BJfhNFfrPUy3EZE90VKT3BlbkFJcbj9y7W1ecH11puQ6ixw'\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=key)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define  the agent (load the LLM and the list of tools)\n",
    "agent = create_tool_calling_agent(llm = llm, tools = tools, prompt = prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, notice how the Agent is decides to use a different tool based on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: Where is Amsterdam?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Amsterdam'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: Amsterdam\n",
      "Summary: Amsterdam ( AM-stÉ™r-dam, UK also  AM-stÉ™r-DAM, Dutch: [ËŒÉ‘mstÉ™rËˆdÉ‘m] ; literally, \"The Dam on the River Amstel\") is the capital and most populated city of the Netherlands. It has a population of 921,402 within the city proper, 1,457,018 in the urban area and 2,480,394 in the metropolitan area. Located in the Dutch province of North Holland, Amsterdam is colloquially referred to as the \"Venice of the North\", for its large number of canals, now a UNESCO World Heritage Site.\n",
      "Amsterdam was founded at the mouth of the Amstel River, which was dammed to control flooding. Originally a small fishing village in the 12th century, Amsterdam became a major world port during the Dutch Golden Age of the 17th century, when the Netherlands was an economic powerhouse. Amsterdam was the leading centre for finance and trade, as well as a hub of secular art production. In the 19th and 20th centuries, the city expanded and new neighborhoods and suburbs were built. The city has a long tradition of openness, liberalism, and tolerance. Cycling is key to the city's modern character, and there are numerous biking paths and lanes spread throughout.\n",
      "Amsterdam's main attractions include its historic canals; the Rijksmuseum, the state museum with Dutch Golden Age art; the Van Gogh Museum; the Dam Square, where the Royal Palace of Amsterdam and former city hall are located; the Amsterdam Museum; Stedelijk Museum, with modern art; the Concertgebouw concert hall; the Anne Frank House; the Scheepvaartmuseum, the Natura Artis Magistra; Hortus Botanicus, NEMO, the red-light district and cannabis coffee shops. The city is known for its nightlife and festival activity, with several nightclubs among the world's most famous. Its artistic heritage, canals and narrow canal houses with gabled faÃ§ades, well-preserved legacies of the city's 17th-century Golden Age, have attracted millions of visitors annually.\n",
      "The Amsterdam Stock Exchange, founded in 1602, is considered the oldest \"modern\" securities market stock exchange in the world. As the commercial capital of the Netherlands and one of the top financial centres in Europe, Amsterdam is considered an alpha world city. The city is the cultural capital of the Netherlands. Many large Dutch institutions have their headquarters in the city. Many of the world's largest companies are based here or have established their European headquarters in the city, such as technology companies Uber, Netflix and Tesla. In 2022, Amsterdam was ranked the ninth-best city to live in by the Economist Intelligence Unit and 12th on quality of living for environment and infrastructure by Mercer. The city was ranked 4th place globally as top tech hub in 2019. The Port of Amsterdam is the fifth largest in Europe. The KLM hub and Amsterdam's main airport, Schiphol, is the busiest airport in the Netherlands, third in Europe, and 11th in the world. The Dutch capital is one of the most multicultural cities in the world, with about 180 nationalities represented. Immigration and ethnic segregation in Amsterdam is a current issue.\n",
      "Amsterdam's notable residents throughout its history include painters Rembrandt and Vincent van Gogh, 17th-century philosophers Baruch Spinoza, John Locke, RenÃ© Descartes, and the Holocaust victim and diarist Anne Frank.\u001b[0m\u001b[32;1m\u001b[1;3mAmsterdam is the capital and most populated city of the Netherlands. It is located in the Dutch province of North Holland. Amsterdam is colloquially referred to as the \"Venice of the North\" due to its large number of canals, which are now a UNESCO World Heritage Site. The city has a population of 921,402 within the city proper, 1,457,018 in the urban area, and 2,480,394 in the metropolitan area.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where is Amsterdam?',\n",
       " 'output': 'Amsterdam is the capital and most populated city of the Netherlands. It is located in the Dutch province of North Holland. Amsterdam is colloquially referred to as the \"Venice of the North\" due to its large number of canals, which are now a UNESCO World Heritage Site. The city has a population of 921,402 within the city proper, 1,457,018 in the urban area, and 2,480,394 in the metropolitan area.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_1 = \"Where is Amsterdam?\"\n",
    "\n",
    "\n",
    "print(f\"Question 1: {question_1}\")\n",
    "agent_executor.invoke({\"input\": question_1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the cureent temperature in Amsterdam?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `weather` with `{'city': 'Amsterdam'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mCurrent temperature in Amsterdam: 12.1Â°C\u001b[0m\u001b[32;1m\u001b[1;3mThe current temperature in Amsterdam is 12.1Â°C.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the cureent temperature in Amsterdam?',\n",
       " 'output': 'The current temperature in Amsterdam is 12.1Â°C.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_2 = \"What is the cureent temperature in Amsterdam?\"\n",
    "\n",
    "print(f\"Question 1: {question_2}\")\n",
    "agent_executor.invoke({\"input\": question_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What should I visit in Amsterdam? Show me an photo\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `{'query': 'Tourist attractions in Amsterdam'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: List of tourist attractions in Amsterdam\n",
      "Summary: Amsterdam, one of Europe's capitals, has many attractions for visitors. The city's most famous sight is the 17th-century canals of Amsterdam (in Dutch: grachtengordel), located in the heart of Amsterdam, have been added to the UNESCO World Heritage List.\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `create_image` with `{'payload': 'Amsterdam tourist attractions'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mimages/image_Amsterdam_tourist_attractions.jpg \u001b[0m\u001b[32;1m\u001b[1;3mAmsterdam offers a variety of attractions for visitors, including the famous 17th-century canals that are a UNESCO World Heritage site. Here is an image showcasing some of the tourist attractions in Amsterdam: \n",
      "\n",
      "![Amsterdam Tourist Attractions](images/image_Amsterdam_tourist_attractions.jpg)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What should I visit in Amsterdam? Show me an photo',\n",
       " 'output': 'Amsterdam offers a variety of attractions for visitors, including the famous 17th-century canals that are a UNESCO World Heritage site. Here is an image showcasing some of the tourist attractions in Amsterdam: \\n\\n![Amsterdam Tourist Attractions](images/image_Amsterdam_tourist_attractions.jpg)'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_3 = \"What should I visit in Amsterdam? Show me an photo\"\n",
    "\n",
    "print(f\"Question 1: {question_3}\")\n",
    "agent_executor.invoke({\"input\": question_3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (a): Build your own agent  <a id='2'></a>\n",
    "The goal is to build an agent that uses the tools you previously developed. Feel free to also use the pre-made tools, available at `helper_functions/tools.py`\n",
    "\n",
    "Task: \n",
    "- A template for defining an agent and an API key are  already provided to your. Build the agent by providing a list of tools, and an LLM `gpt-3.5-turbo-0125`.\n",
    "- Test if the agent gives an output.\n",
    "- Observe how the output changes if you provide less tools in your list of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tools\n",
    "tools = [\n",
    "# TODO: insert your code here\n",
    "]\n",
    "\n",
    "# Load LLM\n",
    "key = 'sk-proj-5BJfhNFfrPUy3EZE90VKT3BlbkFJcbj9y7W1ecH11puQ6ixw'\n",
    "llm = ChatOpenAI(model=\n",
    "                 # TODO: insert your code here\n",
    "                 temperature=0, \n",
    "                 api_key=key)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is. But for now, let's keep it as is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    # TODO: insert your code here\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    # TODO: insert your code here\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (b): Invoke as many tools as you can  <a id='2'></a>\n",
    "Try various prompts to call the agent and follow the generated reasoning process in the response. The goal is to call the agent in a way thay it will use as many tools as possible. \n",
    "\n",
    "Let's see who can reach the highest number of tools used with a single prompt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\n",
    "#TODO: Insert your code here\n",
    "\"\n",
    "\n",
    "print(f\"Question 1: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (b): Optimize the agent prompt  <a id='2'></a>\n",
    "So far we played around with the provided LLM and list of tools. Now let's look into the 3rd component: the Agent promot. \n",
    "\n",
    "Task:\n",
    "- Modify the agent prompt and observe the difference in the output. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
