{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LLM Agents with LangChain\n",
    "\n",
    "Welcome to the workshop on building LLM agents with LangChain!\n",
    "\n",
    "**The goal** \n",
    "\n",
    "With this notebook you will familiarize yourself with the key concepts of an LLM agent. At the end, you will have all the code you need for your very own agent and you will be able to build custom tools for your own use-case. \n",
    "\n",
    "ðŸŒŸ So ... let us begin!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The use case** \n",
    "\n",
    "Summer holidays are coming up and you still don't know where to go. Oh no! \n",
    "\n",
    "You decide to build a tool that helps you get information on holiday locations. For example, you would like to to find out how big a specific city is, what sights are there to see, how the weather there is, and you would like to get a drawing of that place, to get a first impression. Because who does not like art? \n",
    "\n",
    "You will implement this through a sentinent LLM agent, who has access to\n",
    "* the wikipedia API,\n",
    "* a weather API,\n",
    "* can generate images by using a HuggingFace API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The steps**\n",
    "\n",
    "0. [Install dependencies to get the project up and running](#0)\n",
    "1. [Familiarize yourself with the default wikipedia tool](#1)\n",
    "        <ol type=\"a\">\n",
    "        <li>[Explore tool parameters](#1a)</li>\n",
    "        <li>[Run tool and explore output](#1b)</li>\n",
    "        </ol>\n",
    "2. [Build your own tool: weather api](#2)\n",
    "3. Agent exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies <a id='0'></a>\n",
    "\n",
    "Compile the cell below to install the dependencies. Consider clearing the cell output so it does not clutter your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m venv venv         \n",
    "!source venv/bin/activate     \n",
    "!pip3 install -r helper_functions/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update helper_functions.keys.py based on private bin link\n",
    "from helper_functions.keys import WEATHER_KEY, OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Langchain default tool: the [Wikipedia tool](https://python.langchain.com/v0.1/docs/integrations/tools/wikipedia/) <a id='1'></a>\n",
    "\n",
    "The cell below loads the full wikipedia tool. It makes an API call to Wikipedia using the ``WikipediaAPIWrapper`` and returns a summary of the queried article. ``WikipediaQueryRun`` then wraps this into a ready made tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)#, doc_content_chars_max=1000)\n",
    "wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (a): Familiarize yourself with a default tool <a id='1a'></a>\n",
    "\n",
    "Use the methods ``name``, ``description``, ``args``, ``return_direct``, ``metadata`` to familiarize yourself with the parameters of the tool. What is the meaning of the different parameters?\n",
    "\n",
    "Background: each tool is a ``BaseTool`` class object, you can find its definition [here](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.BaseTool.html#langchain_core.tools.BaseTool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Name: \", wiki_tool.name)\n",
    "\n",
    "### TODO: insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1 (b) run tool and explore output <a id='1b'></a>\n",
    "\n",
    "* Use the ``.run(tool_input)`` method to execute the tool. The ``tool_input`` is the search term that you'd like to query wikipedia with.\n",
    "* [Optional] Check out the arguments of the WikipediaAPIWrapper [here](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.wikipedia.WikipediaAPIWrapper.html) and modify its parameters above. How does the output change? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom tools\n",
    "\n",
    "You can build your own tools and don't have to rely on default tools. Tools can be built from any function with the LangChain class method ``StructuredTool.from_function()``(see [here](https://python.langchain.com/v0.1/docs/modules/tools/custom_tools/#structuredtool-dataclass)). The basic elements are\n",
    "* The **function** you would like to be executed when the tool is called\n",
    "* The definition of the **input parameters**\n",
    "* The tool **description**\n",
    "\n",
    "The tool description is especially important, since this is what the agent will use to make the deicion if this tool should be used.\n",
    "\n",
    "Below you see the wikipedia tool, built from the basic elements described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "# define the function\n",
    "def wikipedia_caller(query:str) ->str:\n",
    "    \"\"\"This function queries wikipedia through a search query.\"\"\"\n",
    "    return api_wrapper.run(query)\n",
    "\n",
    "# Input parameter definition\n",
    "class QueryInput(BaseModel):\n",
    "    query: str = Field(description=\"Input search query\")\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        \"A wrapper around Wikipedia. \"\n",
    "        \"Useful for when you need to answer general questions about \"\n",
    "        \"people, places, companies, facts, historical events, or other subjects. \"\n",
    "        \"Input should be a search query.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "my_own_wiki_tool = StructuredTool.from_function(\n",
    "    func=wikipedia_caller,\n",
    "    name=\"wikipedia\",\n",
    "    description=description,\n",
    "    args_schema=QueryInput,\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(my_own_wiki_tool.run('pyladies'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Build your own tool: weather api <a id='2'></a>\n",
    "The goal is to build a tool that extracts weather information from the weather site visualcrossing.com. You typically need an API key to extract information from a website. In this example we provide you with the API key. \n",
    "\n",
    "Task: \n",
    "- The tool function is already provided to your. Build the tool by defining the input parameters and the descriptions. \n",
    "- Turn function, description and input parameters into a tool through ``StructuredTool.from_function()``\n",
    "- test if the tool gives an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests # for API calls\n",
    "\n",
    "# define the function\n",
    "def extract_city_weather(city:str)->str:\n",
    "\n",
    "    # Build the API URL\n",
    "    url = f\"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city}?key={WEATHER_KEY}&unitGroup=metric\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # extract response\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        current_temp = data['days'][0]['temp']\n",
    "        output = f\"Current temperature in {city}: {current_temp}Â°C\"\n",
    "    else:\n",
    "        output = f\"Error: {response.status_code}\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# Input parameter definition\n",
    "class WeatherInput(BaseModel):\n",
    "    # insert your code here\n",
    "\n",
    "# the tool description\n",
    "description: str = (\n",
    "        # TODO: insert your code here\n",
    "    )\n",
    "\n",
    "# fuse the function, input parameters and description into a tool. \n",
    "weather_tool = StructuredTool.from_function(\n",
    "    # TODO: insert your code here\n",
    ")\n",
    "\n",
    "# test the output of the tool\n",
    "print(weather_tool.run('Amsterdam'))\n",
    "\n",
    "# TODO: try generating more ouputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the individual tools into a list. Your collection of tools is not ready to be used by an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [my_own_wiki_tool, weather_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Agents combine the functionality of two components: LLMs and Tools. They empower an LLM to be able to execute additional tasks and reason through a problem. Namely, LLMs have knowlegde on data that was used at time of training. However, they lack knowledge about up-to-date happenings and information. They consist of the following components: \n",
    "- **LLM**: A pre-trained LLM.\n",
    "- **List of tools**: List of tools that give additional functionality to the LLM.\n",
    "- **Prompt**: A description/guideline that is given to the Agent to create \"awareness\" of its purpose.\n",
    "\n",
    "One use case of LLM Agents is to make it possible to have LLMs with access to real time information, like the current weather. Namely, when a prompt is called, agents have an LLM and Tools at their disposal. Based on the prompt, they can deide what would be a better fit for the given prompt: information already available to the LLM, or information that can be fetched with an API (Tool). E.g. for a given prompt \"What is the **usual** temperature in Amsterdam in summer?\", an LLM will likely already have knowledge. However, a prompt \"What is the **cureent** temperature in Amsterdam?\", a weather API would be a better source of information, and in this case the Agent will decide to use the information from a weather tool. If such a tool is not available to the angent, the agent will repsond that the requested information is not available. \n",
    "\n",
    "So, basically, you can think of Agents as usual LLMs but with more \"skills\". Cool, right?\n",
    "\n",
    "Let's see this through an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from langchain_openai import ChatOpenAI # call openAI as agent llm\n",
    "from langchain import hub # for the prompt, we are going to skip this\n",
    "from langchain.agents import create_tool_calling_agent # set up the agent\n",
    "from langchain.agents import AgentExecutor # execute agent\n",
    "\n",
    "\n",
    "from helper_functions.tools import weather_tool, my_own_wiki_tool, image_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tools\n",
    "tools = [my_own_wiki_tool, weather_tool, image_tool]\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0, api_key=OPENAI_KEY)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define  the agent (load the LLM and the list of tools)\n",
    "agent = create_tool_calling_agent(llm = llm, tools = tools, prompt = prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, notice how the Agent is decides to use a different tool based on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"Where is Amsterdam?\"\n",
    "\n",
    "\n",
    "print(f\"Question 1: {question_1}\")\n",
    "agent_executor.invoke({\"input\": question_1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"What is the cureent temperature in Amsterdam?\"\n",
    "\n",
    "print(f\"Question 1: {question_2}\")\n",
    "agent_executor.invoke({\"input\": question_2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_3 = \"What should I visit in Amsterdam? Show me an photo\"\n",
    "\n",
    "print(f\"Question 1: {question_3}\")\n",
    "agent_executor.invoke({\"input\": question_3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (a): Build your own agent  <a id='2'></a>\n",
    "The goal is to build an agent that uses the tools you previously developed. Feel free to also use the pre-made tools, available at `helper_functions/tools.py`\n",
    "\n",
    "Task: \n",
    "- A template for defining an agent and an API key are  already provided to your. Build the agent by providing a list of tools, and an LLM `gpt-3.5-turbo-0125`.\n",
    "- Test if the agent gives an output.\n",
    "- Observe how the output changes if you provide less tools in your list of tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Tools\n",
    "tools = [\n",
    "# TODO: insert your code here\n",
    "]\n",
    "\n",
    "# Load LLM\n",
    "llm = ChatOpenAI(model=\n",
    "                 # TODO: insert your code here\n",
    "                 temperature=0, \n",
    "                 api_key=OPENAI_KEY)\n",
    "\n",
    "# Get the prompt to use - you can modify this! With this you let the agent know what its purpose is. But for now, let's keep it as is.\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages\n",
    "print(type(prompt))\n",
    "\n",
    "# Define the agent and agent executor (load the LLM, the list of tools, and the prompt (descripiton))\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    # TODO: insert your code here\n",
    "    )\n",
    "agent_executor = AgentExecutor(\n",
    "    # TODO: insert your code here\n",
    ")\n",
    "\n",
    "print(\"Your agent is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (b): Invoke as many tools as you can  <a id='2'></a>\n",
    "Try various prompts to call the agent and follow the generated reasoning process in the response. The goal is to call the agent in a way thay it will use as many tools as possible. \n",
    "\n",
    "Let's see who can reach the highest number of tools used with a single prompt! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\n",
    "#TODO: Insert your code here\n",
    "\"\n",
    "\n",
    "print(f\"Question 1: {question}\")\n",
    "agent_executor.invoke({\"input\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3 (b): Optimize the agent prompt  <a id='2'></a>\n",
    "So far we played around with the provided LLM and list of tools. Now let's look into the 3rd component: the Agent promot. \n",
    "\n",
    "Task:\n",
    "- Modify the agent prompt and observe the difference in the output. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
